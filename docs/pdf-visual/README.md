# PDF Visual Comparison Framework (Playwright + Node.js)

## Overview

This project implements a **PDF visual comparison framework** using **Playwright** as the test orchestrator and **Node.js** for document processing.

The framework compares **Output PDFs** against **Baseline PDFs** by:

- Rendering each PDF page to images
- Performing pixel-level visual comparisons
- Detecting page count, layout, and bookmark differences
- Producing a clear, navigable HTML report with visual diffs and metrics

The objective is not only to detect whether PDFs differ, but to **clearly explain why** they differ.

---

## Why Visual Comparison?

PDFs are often regenerated by upstream systems (reporting tools, document generators, CI exports).  
This can introduce subtle but important changes that are not detectable through text extraction alone, such as:

- Font rendering and spacing changes
- Embedded images or regenerated tables
- Layout shifts
- Page order or count changes

Visual comparison ensures that:
- The rendered document matches expectations
- Structural regressions are caught early
- Differences are auditable and easy to reason about

---

## Architecture Overview

The framework is intentionally modular and renderer-agnostic:

### Key Components

- **Rendering**  
  PDFs are rasterized into page images using **Poppler (`pdftoppm`)** for deterministic, production-grade rendering.

- **Comparison**  
  Page images are compared using pixel-based diffing, producing:
  - diff images
  - pixel difference counts
  - percentage difference metrics

- **Metadata Validation**  
  Page count and bookmark (outline) structures are validated independently of visual diffs.

- **Reporting**  
  A standalone HTML report summarizes results and links all generated artifacts.

Playwright is used as the test runner and reporting backbone, even though the comparison itself is Node-based.

---

## Why Poppler (Design Decision)

Initial attempts used `pdfjs` for PDF rendering. However, the provided PDFs contain:

- Embedded raster images
- Hybrid text + image tables
- Engineering-style drawings and watermarks

These characteristics caused rendering failures in Node environments when using `pdfjs`.

**Poppler was chosen because:**
- It provides reliable, deterministic PDF rasterization
- It handles complex image XObjects and color spaces correctly
- It is widely used in production document processing pipelines

This decision prioritizes correctness and stability over a pure JavaScript solution.

---

## Test Data Structure
artifacts/
pdf/
baseline/
sample_file_1_Baseline.pdf
sample_file_2_Baseline.pdf
output/
sample_file_1_Output.pdf
sample_file_2_Output.pdf


Each Output PDF is compared against its corresponding Baseline PDF.

---

## Running the Comparison

### Prerequisites

- Node.js 18+
- Poppler installed and available on PATH

Verify Poppler installation:

```bash
pdftoppm -v
```

Execute PDF Visual Comparison:

```bash
npx playwright test tests/pdf-visual/pdf-compare.spec.ts
```
---

## Output Artifacts

Each run produces a unique, timestamped artifact directory:

artifacts/runs/<run-id>/
  report.html
  summary.json
  sample_file_1/
    baseline/
      page-001.png
    output/
      page-001.png
    diff/
      page-001-diff.png
  sample_file_2/
    ...

Generated Files

1. report.html
    Human-readable report with:

      - PASS / FAIL per PDF pair
      - Page counts
      - Pages with differences
      - Thumbnails and links to baseline, output, and diff images

2. summary.json
   Machine-readable summary of all comparison results

## Pass / Fail Rules

1. A PDF pair is marked FAIL if any of the following conditions are met:

    - Page count mismatch
    - Bookmark (outline) structure mismatch
    - Any page exceeds the configured visual difference threshold

2. For each differing page, the report includes:

    - Page number
    - Pixel difference count
    - Percentage difference relative to page size
    - Visual diff image

## Interpreting the Results

### sample_file_1

- Page counts match (24 vs 24)
- All pages show minor visual differences (â‰¤ ~0.6%)
- Bookmark structure differs between baseline and output
- Although visual differences are relatively small, the consistent diffs across all pages combined with bookmark changes indicate a regenerated document rather than a byte-identical copy.

Result: FAIL

### sample_file_2

- Page count mismatch (5 vs 6)
- Significant visual differences across pages
- Page dimensions differ on some pages
- This represents a clear structural document change.

Result: FAIL

## Notes on Thresholds

- Minor visual differences can occur due to:
- Font rendering changes
- Anti-aliasing
- PDF regeneration without content changes
- Thresholds are configurable and should be tuned based on business risk.
- For this exercise, all detected differences are reported for maximum transparency.

## Future Enhancements

- Potential improvements include:
- Configurable ignore regions for dynamic content
- Semantic text comparison in addition to visual diffing
- CI artifact publishing
- Baseline approval workflows
- PDF metadata normalization
- Performance optimizations for very large documents

## Summary

This framework demonstrates:

- Real-world PDF comparison challenges
- Pragmatic tool selection
- Clear separation of concerns
- Actionable, reviewer-friendly reporting

The focus is on explainability, reliability, and maintainability, rather than simply producing green test results.